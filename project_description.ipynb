{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project for Data Science for Business course: Amazon product reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Product reviews on Amazon are used to support customer purchasing decisions. Reviews and five star ratings represent a reviewer's opinion about a product. Such ratings are subjective: a 5 star represents a best experience with a product and 1 star represents the worst one.  \n",
    "  \n",
    "\n",
    "In this project you will be provided with datasets of product reviews of amazon online shop*. The data is provided in json format. Each item looks like following: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*{\"category\": \"book\", \"reviewerID\": \"A1F6404F1VG29J\", \"asin\": \"B000F83SZQ\", \"reviewerName\": \"Avidreader\", \"helpful\": [0, 0], \"reviewText\": \"I enjoy vintage books and movies so I enjoyed reading this book.  The plot was unusual.  Don't think killing someone in self-defense but leaving the scene and the body without notifying the police or hitting someone in the jaw to knock them out would wash today.Still it was a good read for me.\", \"overall\": 5.0, \"summary\": \"Nice vintage story\", \"unixReviewTime\": 1399248000, \"reviewTime\": \"05 5, 2014\"}*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Field Definitions:\n",
    "* category: category of the product\n",
    "* reviewerID: id of the reviewer\n",
    "* asin: amazon standard identification number which is unique for each product\n",
    "* reviewerName: name of the reviewer\n",
    "* helpful: [x,y] i.e. x is the number of helpful ticks and y is the number of total ticks \n",
    "* reviewText: text of the review\n",
    "* overall: overal rating of the product in the range of [1,2,3,4,5]\n",
    "* summary: a summary of reviewer's opinion about the product\n",
    "* unixReviewTime: time of writing the review in [UNIX format](https://en.wikipedia.org/wiki/Unix_time)\n",
    "* reviewTime: time of writing the review in normal format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Predict the category of each product, based on the **`reviewText`** field. View the problem as a multiclass classification (24 product categories).\n",
    "\n",
    "    f(`reviewText`) -> category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "  \n",
    "Predict whether a product review has 5 stars rating or not (yes/no), based on the `reviewText` field. The dataset for this step is filtered down to the `Digital_Music` category. Construct the problem as a binary classification (rank 5: 1, others: 0).\n",
    "\n",
    "    f(reviewText) -> overall (5 or not)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "Predict the actual number of stars, based on the `reviewText` field. Again, the dataset for this step is filtered down to the `Digital_Music` category. Construct the problem as a multiclass classification (5 categories labeled from 1 to 5).\n",
    "\n",
    "    f(reviewText) -> overall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "You can find the following datasets under project directory in the course git repository:\n",
    "\n",
    "* For step 1: *amazon_step1.json.gz*\n",
    "* For step 2: *amazon_step23.json.gz*\n",
    "* For step 3: *amazon_step23.json.gz*\n",
    "\n",
    "To complete your project, use the following **unseen** datasets to be filled by your final predictive models:\n",
    "\n",
    "* For step 1: *amazon_step1_unseen.csv.gz* (label column to be filled by original product category names)\n",
    "* For step 2: *amazon_step2_unseen.csv.gz* (label column to be filled by 0 and 1) \n",
    "* For step 3: *amazon_step3_unseen.csv.gz* (label column to be filled by 1, 2, 3, 4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "We expect your solution for each step to contain the followings:\n",
    "\n",
    "* data proprocessing and feature extraction (can be shared across different steps)\n",
    "* feature selection (if needed)\n",
    "* train, tune and test at least three models, one in each of the following categories:\n",
    "    * a parametric-based model (i.e. linear models and SVM)\n",
    "    * a similarity-based model (i.e. knn based models)\n",
    "    * an information-based model (i.e. tree based models)\n",
    "* model comparison and arguing about the best model (don't forget mentioning a baseine model)\n",
    "* predict the labels of the unseen test dataset using your best obtained model\n",
    "* discussion on possible additional tasks that can be done to boost the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "\n",
    "* Deliver a Jupyter notebook with an explanation of your methods, codes and results. Don't forget to divide your notebook into different parts, which clearly shows your solution to the common pre-processing as well as different steps separately. \n",
    "    \n",
    "\n",
    "* In each step, fill in the \"unseen\" datasets with your best predictive model and commit the resulting files.  \n",
    "    \n",
    "\n",
    "* Submit your final notebook and files into the git repository of the team using the naming conventions and deadline mentioned in the course syllabus. Each team should build a **new** git repository to submit all project materials.  \n",
    "   \n",
    "\n",
    "* Invite both the course professor (github id: '*KenYounge*') and postdoc (github id: '*omidsh*') to your project git repository.  \n",
    "    \n",
    "\n",
    "* Note in the syllabus that you will also present your solution in the final session of the course - **more details to come.**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips\n",
    "\n",
    "* Presentation of your solutions in a story telling way is extremely important!   \n",
    "  \n",
    "\n",
    "* Document all of your assumptions (e.g. evaluation metric, resampling strategy, ...).  \n",
    "\n",
    "\n",
    "* Make sure your code will run and results are reproducible (fix random seeds, etc.).  \n",
    "\n",
    "\n",
    "*  Comment your blocks of code (and lines of code if needed) and anything in your story/logic that might not be obvious by looking at your code.    \n",
    "\n",
    "\n",
    "* To speed up experimentation, you might use a small sample of the original dataset to do your initial coding. Also try to use all possible cores for computation, by setting the option of n_jobs = 1, when needed. \n",
    "\n",
    "\n",
    "* When possible (and it makes sense), try to take advantage of other fields (e.g. summary field) to improve the performance of your models.\n",
    "\n",
    "\n",
    "* In steps 2 and 3, you try to predict the 'sentiment' of the text. Limiting your dictionary to only subjective words (which contain some sort of sentiment) may be beneficial. You can find online lists for such a purpose. An example of such a list is available [here](http://ptrckprry.com/course/ssd/data/positive-words.txt) for positive words and [here](http://ptrckprry.com/course/ssd/data/negative-words.txt) for negative words. Note that existence of positive and negative words does not necessarily mean that the sentence has positive or negative tone, since other factors such as negation words could affect the sentiments. \n",
    "\n",
    "\n",
    "* Try to be creative and use all available resources to improve your predictions, but don't forget that your line of thinking/reasoning as well as write up of those in each step is equally important.\n",
    "\n",
    "\n",
    "* Your final grade is based on the whole process of doing the project and not just based on your results on the unseen data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "Grading of the project (apart from presentation), is based on the following components:\n",
    "\n",
    "* 25 %  ___ Documentation in your notebook\n",
    "* 15 %  ___ Code quality / comments\n",
    "* 15 %  ___ Pre-processing\n",
    "* 20 %  ___ Step 1\n",
    "* 15 %  ___ Step 2\n",
    "* 10 %  ___ Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Dataset Citation: \n",
    "\n",
    "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering\n",
    "R. He, J. McAuley\n",
    "WWW, 2016"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
